# Query Metrics requires a client certificate
server:
  ssl:
    client-auth: NEED

spring:
  cloud:
    stream:
      bindings:
        queryMetricSource-out-0:
          destination: queryMetricChannel
          producer:
            errorChannelEnabled: true
        queryMetricSink-in-0:
          destination: queryMetricChannel
          group: queryMetricService
    # NOTE: When defining your functions, be sure to include busConsumer, or else spring cloud bus will not work
    function:
      definition: queryMetricSource;queryMetricSink;busConsumer

warehouse-cluster:
  accumulo:
    zookeepers: '${accumulo.zookeepers}'
    instanceName: '${accumulo.instanceName}'
    username: '${accumulo.username}'
    password: '${accumulo.password}'

logging:
  level:
    ROOT: DEBUG
    datawave:
      microservice.querymetric: DEBUG
      iterators: error
      query: error
      ingest: error
      security: error

datawave:
  swagger:
    title: "Query Metric Service"
    description: "REST API provided by the Query Metric Service"
  query:
    metric:
      handler:
        zookeepers: ${warehouse-cluster.accumulo.zookeepers}
        instanceName: ${warehouse-cluster.accumulo.instanceName}
        username: ${warehouse-cluster.accumulo.username}
        password: ${warehouse-cluster.accumulo.password}
        accumuloClientPoolSize: 16
        mapStoreWriteThreads: 1
        numShards: 10
        fieldLengthThreshold: 4049
        shardTableName: datawave.queryMetrics_s
        indexTableName: datawave.queryMetrics_i
        dateIndexTableName: datawave.queryMetrics_di
        reverseIndexTableName: datawave.queryMetrics_r
        metadataTableName: datawave.queryMetrics_m
        metadataDefaultAuths: PUBLIC
        recordWriterMaxMemory: 10
        recordWriterMaxLatency: 16
        recordWriterNumThreads: 4
        enableBloomFilter: false
        queryVisibility: PUBLIC
        defaultMetricVisibility: PUBLIC
        defaultMetricMarkings:
          columnVisibility: PUBLIC
        baseMaps: "{}"
        queryPool: "pool1"
      timely:
        enabled: false
      confirmAckTimeoutMillis: 30000

  # this should be consolidated into a metadata application profile
  metadata:
    all-metadata-auths:
      - PRIVATE
      - PUBLIC
    type-substitutions:
      "[datawave.data.type.DateType]": "datawave.data.type.RawDateType"

  security:
    util:
      subjectDnPattern: "(?:^|,)\\s*OU\\s*=\\s*My Department\\s*(?:,|$)"
      npeOuList: "EXAMPLE_SERVER_OU1,EXAMPLE_SERVER_OU2"

hazelcast:
  client.enabled: false
  server:
    enabled: true
    xml-config: |
      <hazelcast xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                  xsi:schemaLocation="http://www.hazelcast.com/schema/config http://www.hazelcast.com/schema/config/hazelcast-config-5.1.xsd"
                  xmlns="http://www.hazelcast.com/schema/config">
        <map name="incomingQueryMetrics">
          <!-- Keep 1 backup copy of data (so we have 2 copies total) -->
          <backup-count>1</backup-count>
          <!-- Maximum time in seconds for each entry to stay idle in the map. (no get, put, EntryProcessor.process or
               containsKey is called.  Valid values are integers between 0 and Integer.MAX VALUE. Default is 0 / infinite -->
          <max-idle-seconds>600</max-idle-seconds>
          <!-- No matter what, entries get evicted after this time. -->
          <time-to-live-seconds>3600</time-to-live-seconds>
          <merge-policy>com.hazelcast.spi.merge.LatestUpdateMergePolicy</merge-policy>
          <per-entry-stats-enabled>true</per-entry-stats-enabled>
          <!-- Evict the least frequently used entries first if we run out of space and allow 2GB for each cluster node to store data -->
          <eviction eviction-policy="LFU" max-size-policy="USED_HEAP_SIZE" size="2048"/>
          <map-store enabled="true" initial-mode="LAZY">
            <factory-class-name>datawave.microservice.querymetric.persistence.AccumuloMapStore$Factory</factory-class-name>
            <write-delay-seconds>1</write-delay-seconds>
            <write-batch-size>1000</write-batch-size>
          </map-store>
        </map>
        <map name="lastWrittenQueryMetrics">
          <!-- Keep 1 backup copy of data (so we have 2 copies total) -->
          <backup-count>1</backup-count>
          <!-- Maximum time in seconds for each entry to stay idle in the map. (no get, put, EntryProcessor.process or
               containsKey is called.  Valid values are integers between 0 and Integer.MAX VALUE. Default is 0 / infinite -->
          <max-idle-seconds>600</max-idle-seconds>
          <!-- No matter what, entries get evicted after this time. -->
          <time-to-live-seconds>3600</time-to-live-seconds>
          <merge-policy>com.hazelcast.spi.merge.LatestUpdateMergePolicy</merge-policy>
          <per-entry-stats-enabled>true</per-entry-stats-enabled>
          <!-- Evict the least frequently used entries first if we run out of space and allow 2GB for each cluster node to store data -->
          <eviction eviction-policy="LFU" max-size-policy="USED_HEAP_SIZE" size="2048"/>
          <map-store enabled="true" initial-mode="LAZY">
            <factory-class-name>datawave.microservice.querymetric.persistence.AccumuloMapLoader$Factory</factory-class-name>
          </map-store>
        </map>
      </hazelcast>
  clusterName: '${spring.application.name}'
