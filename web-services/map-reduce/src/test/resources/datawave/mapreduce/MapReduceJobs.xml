<beans xmlns="http://www.springframework.org/schema/beans"
	   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	   xmlns:context="http://www.springframework.org/schema/context"
	   xsi:schemaLocation="http://www.springframework.org/schema/beans
                http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
                http://www.springframework.org/schema/context
                http://www.springframework.org/schema/context/spring-context-4.0.xsd">

	<context:property-placeholder system-properties-mode="OVERRIDE" ignore-unresolvable="true" order="100"/>

	<bean id="MapReduceConfiguration" class="datawave.webservice.mr.configuration.MapReduceConfiguration">
	
		<property name="callbackServletURL" value="http://localhost:8080/DataWave/MapReduceStatus/updateState"/>
		<property name="mapReduceBaseDirectory" value="/MapReduceService"/>
		<property name="restrictInputFormats" value="true" />
		<property name="validInputFormats">
			<list value-type="java.lang.Class">
				<value>org.apache.accumulo.core.client.mapreduce.AccumuloInputFormat</value>
			</list>
		</property>
		
		<property name="jobConfiguration">
			<map key-type="java.lang.String" value-type="datawave.webservice.mr.configuration.MapReduceJobConfiguration">
				<entry key="TestJob">
					<bean class="datawave.webservice.mr.configuration.MapReduceJobConfiguration">
						<property name="description" value="MapReduce job that runs a query and either puts the results into a table or files in HDFS" />
						<property name="hdfsUri" value="hdfs://localhost/"/>
						<property name="jobTracker" value="hdfs://localhost:8021"/>
						<property name="requiredRoles">
							<list value-type="java.lang.String">
								<value>AuthorizedUser</value>
							</list>
						</property>
						<property name="classpathJarFiles">
							<list value-type="java.lang.String">
								<!-- Add EJB jars that we need in order to run queries. -->
								<value>vfs:/content/datawave-web-service-${project.version}-${build.env}.ear!datawave-ws-query-${version.datawave}.jar/</value>
								<value>vfs:/content/datawave-web-service-${project.version}-${build.env}.ear!datawave-ws-map-reduce-${version.datawave}.jar/</value>
								<value>vfs:/content/datawave-web-service-${project.version}-${build.env}.ear!datawave-ws-common-${version.datawave}.jar/</value>
								<value>vfs:/content/datawave-web-service-${project.version}-${build.env}.ear!datawave-ws-security-${version.datawave}.jar/</value>
								<!-- Add every jar in the EAR's lib folder. -->
								<value>vfs:/content/datawave-web-service-${project.version}-${build.env}.ear!lib/.*\.jar/</value>
								<!-- Now package up the config module's conf files and include them. -->
								<value>archive:${jboss.modules.dir}/datawave/webservice/configuration/main/conf/!.*</value>
								<!-- Note that all jar files in ${jboss.home.dir}/client/lib and ${jboss.home.dir}/tools/mapreduce/lib are added to the classpath too. -->
							</list>
						</property>
						<property name="requiredRuntimeParameters">
							<map key-type="java.lang.String" value-type="java.lang.Class">
								<entry key="queryId" value="java.lang.String" />
								<entry key="format" value="java.lang.String" />
							</map>
						</property>
						<property name="optionalRuntimeParameters">
							<map key-type="java.lang.String" value-type="java.lang.Class">
								<entry key="outputTableName" value="java.lang.String" />
							</map>
						</property>
						<property name="jobConfigurationProperties">
							<map key-type="java.lang.String" value-type="java.lang.Object">
								<entry key="mapreduce.map.speculative" value="false" />
							</map>
						</property>
						<property name="jobSystemProperties">
							<map key-type="java.lang.String" value-type="java.lang.String">
							</map>
						</property>
						<property name="jobJarName" value="MapReduce.jar"/>
					</bean>
				</entry>
			</map>
		</property>
	</bean>

</beans>